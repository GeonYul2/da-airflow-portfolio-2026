# INTERVIEW STORYLINE

## 1) 60초 자기소개 스크립트

“저는 SQL/Python 기반으로 재무·매출 지표를 자동화하는 데이터 분석 포트폴리오를 만들었습니다.  
이 프로젝트에서 Airflow DAG로 raw 적재부터 KPI 산출, 정합성 검사, 리포트 생성까지 일 배치를 구성했고,  
Daily/Weekly/Monthly KPI와 Region/Channel 세그먼트 분석을 제공했습니다.  
특히 품질검사 실패 시 DAG를 실패 처리하고 검사 이력을 별도 테이블에 저장해 운영 관점까지 반영했습니다.  
또한 Postgres와 MariaDB 두 환경에서 동일 파이프라인이 동작하도록 구성해 실무 적응력을 보여주고자 했습니다.”

---

## 2) STAR 사례 1 — KPI 자동화

### S (상황)
수작업 엑셀 집계는 느리고 오류가 잦아, 월/분기 재무 리포트 정확도와 속도가 떨어질 수 있는 상황.

### T (과제)
일별 매출/환불/순매출/마진 KPI를 자동으로 계산하고, 주/월 롤업까지 일관되게 제공.

### A (행동)
- SQL 레이어를 `raw → staging → mart → KPI`로 분리
- Airflow DAG에서 단계별 태스크 체인 구성
- 결과물(CSV/HTML/요약 리포트) 자동 생성

### R (결과)
- 반복 보고 작업 자동화
- KPI 계산 로직이 코드/문서로 표준화됨
- 경영진/유관부서 공유용 산출물 생성 시간 단축

---

## 3) STAR 사례 2 — 데이터 정합성 운영

### S
데이터 적재 성공만으로는 분석 품질을 보장할 수 없음.

### T
정합성 이슈를 조기 감지하고, 실패 원인을 추적 가능하게 만들기.

### A
- null/중복/참조무결성/이상치 검사 SQL 구현
- `run_quality_checks`에서 실패 시 DAG fail
- 검사 결과를 `quality_check_runs`에 저장

### R
- “실패했는지”뿐 아니라 “왜 실패했는지”를 이력으로 확인 가능
- 재실행/복구 절차가 명확해져 운영 안정성 향상

---

## 4) STAR 사례 3 — 실무 적응성(멀티 DB)

### S
회사마다 사용하는 DBMS가 달라 이식성이 필요함.

### T
동일 파이프라인을 Postgres/MariaDB 모두에서 실행 가능하게 만들기.

### A
- `WAREHOUSE_DSN` 기반 DB 연결 분기
- `SQL_ROOT`로 SQL dialect 레이어 분리 (`sql/`, `sql/mysql/`)
- Postgres/MySQL 각각 실제 실행 검증

### R
- 환경 전환 비용 감소
- DB 차이에 대한 대응 경험을 포트폴리오로 증명

---

## 5) 예상 질문 & 답변 포인트

### Q1. 왜 Airflow를 선택했나요?
- 배치 의존성 관리, 실패 재시도, 스케줄링, 모니터링이 내장되어 운영형 분석 파이프라인에 적합.

### Q2. 데이터 품질은 어떻게 보장했나요?
- 품질 SQL + 실패 시 DAG 중단 + 검사 이력 저장(감사 가능성).

### Q3. SQL 실력을 어떻게 보여줄 수 있나요?
- 계층형 모델링(staging/mart), KPI 정의 SQL, 주/월 롤업, 세그먼트 집계, 참조 무결성 검증 SQL로 설명.

### Q4. 이 프로젝트를 입사 후 어떻게 확장할 건가요?
- 지표 정의서 고도화, 대시보드 연결(BI), 알림/이상탐지 자동화, 데이터 계약/테스트 확대.

---

## 6) 10분 발표 구성 (권장)

1. 프로젝트 목표/배경 (1분)
2. 아키텍처 다이어그램 설명 (2분)
3. DAG 실행 흐름 + 결과물 확인 (3분)
4. 품질 실패 데모 및 복구 (2분)
5. 회고/입사 후 확장 계획 (2분)

---

## 7) 마지막 한 줄 (면접 마무리 멘트)

“저는 단순 분석을 넘어서, **정확한 지표를 반복 가능하게 전달하는 자동화 시스템**을 만드는 데이터 분석가가 되고 싶습니다.”
